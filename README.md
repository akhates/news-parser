### Формулировка задачи
Большинство веб-страниц сейчас перегружено всевозможной рекламой... Наша задача «вытащить» из веб-страницы только полезную информацию, отбросив весь «мусор» (навигацию, рекламу и тд).

Полученный текст нужно отформатировать для максимально комфортного чтения в любом текстовом редакторе. Правила форматирования:

ширина строки не больше 80 символов (еслибольше, переносим по словам), абзацы и заголовки отбиваются пустой строкой.
Если в тексте встречаются ссылки, то URL вставить в текст в квадратных скобках. Остальные правила на ваше усмотрение.
Программа оформляется в виде утилиты командной строки, которой в качестве параметра указывается произвольный URL. Она извлекает по этому URL страницу, обрабатывает ее и формирует текстовый файл с текстом статьи, представленной на данной странице.

В качестве примера можно взять любую статью на lenta.ru, gazeta.ru и тд

Алгоритм должен быть максимально универсальным, то есть работать на большинстве сайтов.

Таск 1*: Имя выходного файла должно формироваться автоматически по URL. Примерно так: http://lenta.ru/news/2013/03/dtp/index.html => [CUR_DIR]/lenta.ru/news/2013/03/dtp/index.txt

Таск 2*: Программа должна поддаваться настройке – в отдельном файле/файлах задаются шаблоны обработки страниц.

### Требования к выполнению задачи
1. Задача выполняется на С++|Python с использованием классов. Не должно использоваться
сторонних библиотек, впрямую решающих задачу.
2. Предпочтительная среда выполнения – MS Windows.
3. Решение должно состоять из документа, описывающего алгоритм, исходных кодов
программы, исполняемого модуля.
4. Приложите список URL, на которых вы проверяли свое решение. И результаты проверки.
5. Желательно указать направление дальнейшего улучшения/развития программы.

#### Алгоритм работы

Предельно простая регулярка `(re.findall(r'<p>(.*?)</p>'))`. Работает потому что большинство (по крайней мере новостных) сайтов используют wyswyg редакторы, 
которые автоматически заворачивают текст в параграфы.

#### Примеры
https://lenta.ru/news/2016/07/01/vapersong/ <br>
https://www.gazeta.ru/business/2021/08/11/13856210.shtml <br>
Можно просмотреть в соответствующих папках в репо

#### Использование
*  ссылка на статью либо --random для случайной статьи (один из сайтов в settings.json)

#### Дальнейшие планы по улучшению
Сделать более точную проверку, чтобы уменьшить количество летящего мусора.
Много сайтов используют React которому требуется js-runtime иначе все что он будет возвращать это: <br>
`<noscript>You need to enable JavaScript to see this page</noscript>` <br>
Избежать этого можно если использовать Selenium и отрендерить страницу прежде чем парсить ее.
<br>
Ну а вообще большие компании используют машинное обучение для задач таких как эта, учитывая насколько хаотичен интернет и то что каждый делает сайты по своему.
